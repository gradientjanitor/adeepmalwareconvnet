import numpy as np
import gzip
import random

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Activation
from keras.layers import Conv1D, MaxPooling1D, BatchNormalization

# make a dict containing keys and classes.
def load_labels(path):
    labels = []
    for l in open(path):
        uid, label = l.split(",")

        # get rid of ""'s
        uid = uid[1:-1]

        labels.append((uid, label))

    return np.asarray(labels)


# thanks to https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly for quickly getting
# me going on data generators at 1am
class MalwareGenerator(keras.utils.Sequence):
    def __init__(self, samples, batchsz=32, nchunks=32, chunksz=1024, n_classes=10):
        self.nchunks = nchunks
        self.chunksz = chunksz
        self.batchsz = batchsz
        self.samples = samples

        self.n_classes = n_classes
        self.on_epoch_end()

    def __len__(self):
        return len(self.samples) // self.batchsz

    def __getitem__(self, index):
        samples_batch = self.samples[self.sidxs[index*self.batchsz : (index+1)*self.batchsz]]
        x, y = self.__data_generation(samples_batch)
        return x, y

    def on_epoch_end(self):
        self.sidxs = np.random.permutation(len(self.samples))

    def __data_generation(self, samples):
        data = np.zeros((len(samples), self.nchunks*self.chunksz, 8), dtype=np.float32)
        labels = np.zeros((len(samples)), dtype=np.int64)

        for sidx, sample in enumerate(samples):
            uid, label = sample
    
            try:
                sample_binary = gzip.open("malware_data/%s.gz" % uid, "rb").read()
            except:
                continue
    
            labels[sidx] = label
    
            # pad sample binary out to nearest chunksz
            padding = int(np.ceil(len(sample_binary) / self.chunksz) * self.chunksz - len(sample_binary))
            sample_binary += b"\x00" * padding
    
            # recast as np array so we can do some reshaping
            sample_binary = np.frombuffer(sample_binary, dtype=np.uint8)
            sample_binary = sample_binary.reshape(-1, self.chunksz)
    
            # randomly nchunks from sample of size chunksz 
            chunk_sel = np.sort(np.random.permutation(sample_binary.shape[0])[:self.nchunks])
            sample_binary = sample_binary[chunk_sel,:]
    
            sample_binary = np.unpackbits(sample_binary)
            sample_binary = sample_binary.reshape(-1,8).astype(np.float32)
    
            data[sidx,:sample_binary.shape[0],:] = 2*sample_binary-1
    
        y = keras.utils.to_categorical(labels, 10)
        return data, y


label_path = "trainLabels.csv"

train_percentage = 0.8
labels = load_labels(label_path)
random.shuffle(labels)

train_samps = int(train_percentage * len(labels))

train_labels = labels[:train_samps]
val_labels = labels[train_samps:]

nchunks = 128
chunksz = 1024

model = Sequential()
model.add(Conv1D(32, kernel_size=5, input_shape=(nchunks*chunksz,8)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv1D(64, kernel_size=5))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv1D(128, kernel_size=5))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(10))
model.compile(loss=keras.losses.categorical_crossentropy,
        optimizer=keras.optimizers.Adam(),
        metrics=['accuracy'])

train_gen = MalwareGenerator(train_labels, chunksz=chunksz, nchunks=nchunks)
val_gen = MalwareGenerator(val_labels, chunksz=chunksz, nchunks=nchunks)

model.fit_generator(generator=train_gen, validation_data=val_gen,
        use_multiprocessing=True, workers=4)
